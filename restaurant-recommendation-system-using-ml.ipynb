{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-03-27T12:17:05.967888Z",
     "iopub.status.busy": "2021-03-27T12:17:05.967191Z",
     "iopub.status.idle": "2021-03-27T12:17:08.237314Z",
     "shell.execute_reply": "2021-03-27T12:17:08.236015Z"
    },
    "papermill": {
     "duration": 2.283055,
     "end_time": "2021-03-27T12:17:08.237671",
     "exception": false,
     "start_time": "2021-03-27T12:17:05.954616",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import r2_score\n",
    "import warnings\n",
    "warnings.filterwarnings('always')\n",
    "warnings.filterwarnings('ignore')\n",
    "import re\n",
    "# from nltk.corpus import stopwords\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-27T12:17:08.296542Z",
     "iopub.status.busy": "2021-03-27T12:17:08.295701Z",
     "iopub.status.idle": "2021-03-27T12:17:20.451112Z",
     "shell.execute_reply": "2021-03-27T12:17:20.450392Z"
    },
    "papermill": {
     "duration": 12.175018,
     "end_time": "2021-03-27T12:17:20.451305",
     "exception": false,
     "start_time": "2021-03-27T12:17:08.276287",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>address</th>\n",
       "      <th>name</th>\n",
       "      <th>online_order</th>\n",
       "      <th>book_table</th>\n",
       "      <th>rate</th>\n",
       "      <th>votes</th>\n",
       "      <th>phone</th>\n",
       "      <th>location</th>\n",
       "      <th>rest_type</th>\n",
       "      <th>dish_liked</th>\n",
       "      <th>cuisines</th>\n",
       "      <th>approx_cost(for two people)</th>\n",
       "      <th>reviews_list</th>\n",
       "      <th>menu_item</th>\n",
       "      <th>listed_in(type)</th>\n",
       "      <th>listed_in(city)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.zomato.com/bangalore/jalsa-banasha...</td>\n",
       "      <td>942, 21st Main Road, 2nd Stage, Banashankari, ...</td>\n",
       "      <td>Jalsa</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>4.1/5</td>\n",
       "      <td>775</td>\n",
       "      <td>080 42297555\\r\\n+91 9743772233</td>\n",
       "      <td>Banashankari</td>\n",
       "      <td>Casual Dining</td>\n",
       "      <td>Pasta, Lunch Buffet, Masala Papad, Paneer Laja...</td>\n",
       "      <td>North Indian, Mughlai, Chinese</td>\n",
       "      <td>800</td>\n",
       "      <td>[('Rated 4.0', 'RATED\\n  A beautiful place to ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>Buffet</td>\n",
       "      <td>Banashankari</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.zomato.com/bangalore/spice-elephan...</td>\n",
       "      <td>2nd Floor, 80 Feet Road, Near Big Bazaar, 6th ...</td>\n",
       "      <td>Spice Elephant</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>4.1/5</td>\n",
       "      <td>787</td>\n",
       "      <td>080 41714161</td>\n",
       "      <td>Banashankari</td>\n",
       "      <td>Casual Dining</td>\n",
       "      <td>Momos, Lunch Buffet, Chocolate Nirvana, Thai G...</td>\n",
       "      <td>Chinese, North Indian, Thai</td>\n",
       "      <td>800</td>\n",
       "      <td>[('Rated 4.0', 'RATED\\n  Had been here for din...</td>\n",
       "      <td>[]</td>\n",
       "      <td>Buffet</td>\n",
       "      <td>Banashankari</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.zomato.com/SanchurroBangalore?cont...</td>\n",
       "      <td>1112, Next to KIMS Medical College, 17th Cross...</td>\n",
       "      <td>San Churro Cafe</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>3.8/5</td>\n",
       "      <td>918</td>\n",
       "      <td>+91 9663487993</td>\n",
       "      <td>Banashankari</td>\n",
       "      <td>Cafe, Casual Dining</td>\n",
       "      <td>Churros, Cannelloni, Minestrone Soup, Hot Choc...</td>\n",
       "      <td>Cafe, Mexican, Italian</td>\n",
       "      <td>800</td>\n",
       "      <td>[('Rated 3.0', \"RATED\\n  Ambience is not that ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>Buffet</td>\n",
       "      <td>Banashankari</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.zomato.com/bangalore/addhuri-udupi...</td>\n",
       "      <td>1st Floor, Annakuteera, 3rd Stage, Banashankar...</td>\n",
       "      <td>Addhuri Udupi Bhojana</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>3.7/5</td>\n",
       "      <td>88</td>\n",
       "      <td>+91 9620009302</td>\n",
       "      <td>Banashankari</td>\n",
       "      <td>Quick Bites</td>\n",
       "      <td>Masala Dosa</td>\n",
       "      <td>South Indian, North Indian</td>\n",
       "      <td>300</td>\n",
       "      <td>[('Rated 4.0', \"RATED\\n  Great food and proper...</td>\n",
       "      <td>[]</td>\n",
       "      <td>Buffet</td>\n",
       "      <td>Banashankari</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.zomato.com/bangalore/grand-village...</td>\n",
       "      <td>10, 3rd Floor, Lakshmi Associates, Gandhi Baza...</td>\n",
       "      <td>Grand Village</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>3.8/5</td>\n",
       "      <td>166</td>\n",
       "      <td>+91 8026612447\\r\\n+91 9901210005</td>\n",
       "      <td>Basavanagudi</td>\n",
       "      <td>Casual Dining</td>\n",
       "      <td>Panipuri, Gol Gappe</td>\n",
       "      <td>North Indian, Rajasthani</td>\n",
       "      <td>600</td>\n",
       "      <td>[('Rated 4.0', 'RATED\\n  Very good restaurant ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>Buffet</td>\n",
       "      <td>Banashankari</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 url  \\\n",
       "0  https://www.zomato.com/bangalore/jalsa-banasha...   \n",
       "1  https://www.zomato.com/bangalore/spice-elephan...   \n",
       "2  https://www.zomato.com/SanchurroBangalore?cont...   \n",
       "3  https://www.zomato.com/bangalore/addhuri-udupi...   \n",
       "4  https://www.zomato.com/bangalore/grand-village...   \n",
       "\n",
       "                                             address                   name  \\\n",
       "0  942, 21st Main Road, 2nd Stage, Banashankari, ...                  Jalsa   \n",
       "1  2nd Floor, 80 Feet Road, Near Big Bazaar, 6th ...         Spice Elephant   \n",
       "2  1112, Next to KIMS Medical College, 17th Cross...        San Churro Cafe   \n",
       "3  1st Floor, Annakuteera, 3rd Stage, Banashankar...  Addhuri Udupi Bhojana   \n",
       "4  10, 3rd Floor, Lakshmi Associates, Gandhi Baza...          Grand Village   \n",
       "\n",
       "  online_order book_table   rate  votes                             phone  \\\n",
       "0          Yes        Yes  4.1/5    775    080 42297555\\r\\n+91 9743772233   \n",
       "1          Yes         No  4.1/5    787                      080 41714161   \n",
       "2          Yes         No  3.8/5    918                    +91 9663487993   \n",
       "3           No         No  3.7/5     88                    +91 9620009302   \n",
       "4           No         No  3.8/5    166  +91 8026612447\\r\\n+91 9901210005   \n",
       "\n",
       "       location            rest_type  \\\n",
       "0  Banashankari        Casual Dining   \n",
       "1  Banashankari        Casual Dining   \n",
       "2  Banashankari  Cafe, Casual Dining   \n",
       "3  Banashankari          Quick Bites   \n",
       "4  Basavanagudi        Casual Dining   \n",
       "\n",
       "                                          dish_liked  \\\n",
       "0  Pasta, Lunch Buffet, Masala Papad, Paneer Laja...   \n",
       "1  Momos, Lunch Buffet, Chocolate Nirvana, Thai G...   \n",
       "2  Churros, Cannelloni, Minestrone Soup, Hot Choc...   \n",
       "3                                        Masala Dosa   \n",
       "4                                Panipuri, Gol Gappe   \n",
       "\n",
       "                         cuisines approx_cost(for two people)  \\\n",
       "0  North Indian, Mughlai, Chinese                         800   \n",
       "1     Chinese, North Indian, Thai                         800   \n",
       "2          Cafe, Mexican, Italian                         800   \n",
       "3      South Indian, North Indian                         300   \n",
       "4        North Indian, Rajasthani                         600   \n",
       "\n",
       "                                        reviews_list menu_item  \\\n",
       "0  [('Rated 4.0', 'RATED\\n  A beautiful place to ...        []   \n",
       "1  [('Rated 4.0', 'RATED\\n  Had been here for din...        []   \n",
       "2  [('Rated 3.0', \"RATED\\n  Ambience is not that ...        []   \n",
       "3  [('Rated 4.0', \"RATED\\n  Great food and proper...        []   \n",
       "4  [('Rated 4.0', 'RATED\\n  Very good restaurant ...        []   \n",
       "\n",
       "  listed_in(type) listed_in(city)  \n",
       "0          Buffet    Banashankari  \n",
       "1          Buffet    Banashankari  \n",
       "2          Buffet    Banashankari  \n",
       "3          Buffet    Banashankari  \n",
       "4          Buffet    Banashankari  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zomato_real=pd.read_csv(\"./zomato.csv\")\n",
    "zomato_real.head() # prints the first 5 rows of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-27T12:17:20.522672Z",
     "iopub.status.busy": "2021-03-27T12:17:20.520337Z",
     "iopub.status.idle": "2021-03-27T12:19:00.382437Z",
     "shell.execute_reply": "2021-03-27T12:19:00.381775Z"
    },
    "papermill": {
     "duration": 99.898883,
     "end_time": "2021-03-27T12:19:00.382606",
     "exception": false,
     "start_time": "2021-03-27T12:17:20.483723",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Deleting Unnnecessary Columns\n",
    "zomato=zomato_real.drop(['url','dish_liked','phone'],axis=1) #Dropping the column \"dish_liked\", \"phone\", \"url\" and saving the new dataset as \"zomato\"\n",
    "\n",
    "#Removing the Duplicates\n",
    "zomato.duplicated().sum()\n",
    "zomato.drop_duplicates(inplace=True)\n",
    "\n",
    "#Remove the NaN values from the dataset\n",
    "zomato.isnull().sum()\n",
    "zomato.dropna(how='any',inplace=True)\n",
    "\n",
    "#Changing the column names\n",
    "zomato = zomato.rename(columns={'approx_cost(for two people)':'cost','listed_in(type)':'type', 'listed_in(city)':'city'})\n",
    "\n",
    "#Some Transformations\n",
    "zomato['cost'] = zomato['cost'].astype(str) #Changing the cost to string\n",
    "zomato['cost'] = zomato['cost'].apply(lambda x: x.replace(',','.')) #Using lambda function to replace ',' from cost\n",
    "zomato['cost'] = zomato['cost'].astype(float)\n",
    "#Removing '/5' from Rates\n",
    "zomato = zomato.loc[zomato.rate !='NEW']\n",
    "zomato = zomato.loc[zomato.rate !='-'].reset_index(drop=True)\n",
    "remove_slash = lambda x: x.replace('/5', '') if type(x) == np.str else x\n",
    "zomato.rate = zomato.rate.apply(remove_slash).str.strip().astype('float')\n",
    "\n",
    "# Adjust the column names\n",
    "zomato.name = zomato.name.apply(lambda x:x.title())\n",
    "zomato.online_order.replace(('Yes','No'),(True, False),inplace=True)\n",
    "zomato.book_table.replace(('Yes','No'),(True, False),inplace=True)\n",
    "\n",
    "## Computing Mean Rating\n",
    "restaurants = list(zomato['name'].unique())\n",
    "zomato['Mean Rating'] = 0\n",
    "\n",
    "for i in range(len(restaurants)):\n",
    "    zomato['Mean Rating'][zomato['name'] == restaurants[i]] = zomato['rate'][zomato['name'] == restaurants[i]].mean()\n",
    "    \n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler(feature_range = (1,5))\n",
    "zomato[['Mean Rating']] = scaler.fit_transform(zomato[['Mean Rating']]).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-27T12:19:00.443348Z",
     "iopub.status.busy": "2021-03-27T12:19:00.435366Z",
     "iopub.status.idle": "2021-03-27T12:20:07.232610Z",
     "shell.execute_reply": "2021-03-27T12:20:07.233136Z"
    },
    "papermill": {
     "duration": 66.8175,
     "end_time": "2021-03-27T12:20:07.233321",
     "exception": false,
     "start_time": "2021-03-27T12:19:00.415821",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "LookupError",
     "evalue": "\n**********************************************************************\n  Resource \u001b[93mstopwords\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('stopwords')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mcorpora/stopwords\u001b[0m\n\n  Searched in:\n    - '/Users/ctrlscrpt/nltk_data'\n    - '/opt/homebrew/opt/python@3.9/Frameworks/Python.framework/Versions/3.9/nltk_data'\n    - '/opt/homebrew/opt/python@3.9/Frameworks/Python.framework/Versions/3.9/share/nltk_data'\n    - '/opt/homebrew/opt/python@3.9/Frameworks/Python.framework/Versions/3.9/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/nltk/corpus/util.py\u001b[0m in \u001b[0;36m__load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     83\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m                     \u001b[0mroot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{self.subdir}/{zip_name}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/nltk/data.py\u001b[0m in \u001b[0;36mfind\u001b[0;34m(resource_name, paths)\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0mresource_not_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"\\n{sep}\\n{msg}\\n{sep}\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 583\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_not_found\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    584\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mstopwords\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('stopwords')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mcorpora/stopwords.zip/stopwords/\u001b[0m\n\n  Searched in:\n    - '/Users/ctrlscrpt/nltk_data'\n    - '/opt/homebrew/opt/python@3.9/Frameworks/Python.framework/Versions/3.9/nltk_data'\n    - '/opt/homebrew/opt/python@3.9/Frameworks/Python.framework/Versions/3.9/share/nltk_data'\n    - '/opt/homebrew/opt/python@3.9/Frameworks/Python.framework/Versions/3.9/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/7x/lpk1lsb50sxf2_96njh4pkg80000gn/T/ipykernel_89528/2879019658.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m## Removal of Stopwords\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorpus\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mstopwords\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mSTOPWORDS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstopwords\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'english'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mremove_stopwords\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;34m\"\"\"custom function to remove the stopwords\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/nltk/corpus/util.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, attr)\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"LazyCorpusLoader object has no attribute '__bases__'\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m         \u001b[0;31m# This looks circular, but its not, since __load() changes our\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0;31m# __class__ to something new:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/nltk/corpus/util.py\u001b[0m in \u001b[0;36m__load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     84\u001b[0m                     \u001b[0mroot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{self.subdir}/{zip_name}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m         \u001b[0;31m# Load the corpus.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/nltk/corpus/util.py\u001b[0m in \u001b[0;36m__load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m                 \u001b[0mroot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{self.subdir}/{self.__name}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mLookupError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/homebrew/lib/python3.9/site-packages/nltk/data.py\u001b[0m in \u001b[0;36mfind\u001b[0;34m(resource_name, paths)\u001b[0m\n\u001b[1;32m    581\u001b[0m     \u001b[0msep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"*\"\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m70\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0mresource_not_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"\\n{sep}\\n{msg}\\n{sep}\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 583\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_not_found\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    584\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mstopwords\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('stopwords')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mcorpora/stopwords\u001b[0m\n\n  Searched in:\n    - '/Users/ctrlscrpt/nltk_data'\n    - '/opt/homebrew/opt/python@3.9/Frameworks/Python.framework/Versions/3.9/nltk_data'\n    - '/opt/homebrew/opt/python@3.9/Frameworks/Python.framework/Versions/3.9/share/nltk_data'\n    - '/opt/homebrew/opt/python@3.9/Frameworks/Python.framework/Versions/3.9/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************\n"
     ]
    }
   ],
   "source": [
    "## Lower Casing\n",
    "zomato[\"reviews_list\"] = zomato[\"reviews_list\"].str.lower()\n",
    "\n",
    "## Removal of Puctuations\n",
    "import string\n",
    "PUNCT_TO_REMOVE = string.punctuation\n",
    "def remove_punctuation(text):\n",
    "    \"\"\"custom function to remove the punctuation\"\"\"\n",
    "    return text.translate(str.maketrans('', '', PUNCT_TO_REMOVE))\n",
    "\n",
    "zomato[\"reviews_list\"] = zomato[\"reviews_list\"].apply(lambda text: remove_punctuation(text))\n",
    "\n",
    "## Removal of Stopwords\n",
    "from nltk.corpus import stopwords\n",
    "STOPWORDS = set(stopwords.words('english'))\n",
    "def remove_stopwords(text):\n",
    "    \"\"\"custom function to remove the stopwords\"\"\"\n",
    "    return \" \".join([word for word in str(text).split() if word not in STOPWORDS])\n",
    "\n",
    "zomato[\"reviews_list\"] = zomato[\"reviews_list\"].apply(lambda text: remove_stopwords(text))\n",
    "\n",
    "## Removal of URLS\n",
    "def remove_urls(text):\n",
    "    url_pattern = re.compile(r'https?://\\S+|www\\.\\S+')\n",
    "    return url_pattern.sub(r'', text)\n",
    "\n",
    "zomato[\"reviews_list\"] = zomato[\"reviews_list\"].apply(lambda text: remove_urls(text))\n",
    "\n",
    "zomato[['reviews_list', 'cuisines']].sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-27T12:20:07.268026Z",
     "iopub.status.busy": "2021-03-27T12:20:07.267264Z",
     "iopub.status.idle": "2021-03-27T12:20:07.290198Z",
     "shell.execute_reply": "2021-03-27T12:20:07.289458Z"
    },
    "papermill": {
     "duration": 0.045971,
     "end_time": "2021-03-27T12:20:07.290351",
     "exception": false,
     "start_time": "2021-03-27T12:20:07.244380",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# RESTAURANT NAMES:\n",
    "restaurant_names = list(zomato['name'].unique())\n",
    "def get_top_words(column, top_nu_of_words, nu_of_word):\n",
    "    vec = CountVectorizer(ngram_range= nu_of_word, stop_words='english')\n",
    "    bag_of_words = vec.fit_transform(column)\n",
    "    sum_words = bag_of_words.sum(axis=0)\n",
    "    words_freq = [(word, sum_words[0, idx]) for word, idx in vec.vocabulary_.items()]\n",
    "    words_freq =sorted(words_freq, key = lambda x: x[1], reverse=True)\n",
    "    return words_freq[:top_nu_of_words]\n",
    "    \n",
    "zomato=zomato.drop(['address','rest_type', 'type', 'menu_item', 'votes'],axis=1)\n",
    "import pandas\n",
    "\n",
    "# Randomly sample 60% of your dataframe\n",
    "df_percent = zomato.sample(frac=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-27T12:20:07.351984Z",
     "iopub.status.busy": "2021-03-27T12:20:07.344461Z",
     "iopub.status.idle": "2021-03-27T12:22:33.019880Z",
     "shell.execute_reply": "2021-03-27T12:22:33.019157Z"
    },
    "papermill": {
     "duration": 145.695113,
     "end_time": "2021-03-27T12:22:33.020088",
     "exception": false,
     "start_time": "2021-03-27T12:20:07.324975",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_percent.set_index('name', inplace=True)\n",
    "indices = pd.Series(df_percent.index)\n",
    "\n",
    "# Creating tf-idf matrix\n",
    "tfidf = TfidfVectorizer(analyzer='word', ngram_range=(1, 2), min_df=0, stop_words='english')\n",
    "tfidf_matrix = tfidf.fit_transform(df_percent['reviews_list'])\n",
    "\n",
    "cosine_similarities = linear_kernel(tfidf_matrix, tfidf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-03-27T12:22:33.086078Z",
     "iopub.status.busy": "2021-03-27T12:22:33.085371Z",
     "iopub.status.idle": "2021-03-27T12:22:33.443865Z",
     "shell.execute_reply": "2021-03-27T12:22:33.445083Z"
    },
    "papermill": {
     "duration": 0.389456,
     "end_time": "2021-03-27T12:22:33.445357",
     "exception": false,
     "start_time": "2021-03-27T12:22:33.055901",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOP 8 RESTAURANTS LIKE Pai Vihar WITH SIMILAR REVIEWS: \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cuisines</th>\n",
       "      <th>Mean Rating</th>\n",
       "      <th>cost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Srinidhi Veg Food Court</th>\n",
       "      <td>Chinese, North Indian, South Indian</td>\n",
       "      <td>3.71</td>\n",
       "      <td>300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Samosa Singh</th>\n",
       "      <td>Street Food, Beverages</td>\n",
       "      <td>3.60</td>\n",
       "      <td>150.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Samosa Singh</th>\n",
       "      <td>North Indian, Mithai</td>\n",
       "      <td>3.60</td>\n",
       "      <td>250.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Prasiddhi Food Corner</th>\n",
       "      <td>Fast Food, North Indian, South Indian</td>\n",
       "      <td>3.45</td>\n",
       "      <td>200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mayura Sagar</th>\n",
       "      <td>Chinese, North Indian, South Indian</td>\n",
       "      <td>3.32</td>\n",
       "      <td>250.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kidambi'S Kitchen</th>\n",
       "      <td>South Indian</td>\n",
       "      <td>3.17</td>\n",
       "      <td>300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Juba Cafe</th>\n",
       "      <td>Juices</td>\n",
       "      <td>3.06</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Udupi Grand</th>\n",
       "      <td>South Indian, North Indian, Chinese</td>\n",
       "      <td>2.91</td>\n",
       "      <td>300.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      cuisines  Mean Rating  \\\n",
       "Srinidhi Veg Food Court    Chinese, North Indian, South Indian         3.71   \n",
       "Samosa Singh                            Street Food, Beverages         3.60   \n",
       "Samosa Singh                              North Indian, Mithai         3.60   \n",
       "Prasiddhi Food Corner    Fast Food, North Indian, South Indian         3.45   \n",
       "Mayura Sagar               Chinese, North Indian, South Indian         3.32   \n",
       "Kidambi'S Kitchen                                 South Indian         3.17   \n",
       "Juba Cafe                                               Juices         3.06   \n",
       "Udupi Grand                South Indian, North Indian, Chinese         2.91   \n",
       "\n",
       "                          cost  \n",
       "Srinidhi Veg Food Court  300.0  \n",
       "Samosa Singh             150.0  \n",
       "Samosa Singh             250.0  \n",
       "Prasiddhi Food Corner    200.0  \n",
       "Mayura Sagar             250.0  \n",
       "Kidambi'S Kitchen        300.0  \n",
       "Juba Cafe                100.0  \n",
       "Udupi Grand              300.0  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def recommend(name, cosine_similarities = cosine_similarities):\n",
    "    \n",
    "    # Create a list to put top restaurants\n",
    "    recommend_restaurant = []\n",
    "    \n",
    "    # Find the index of the hotel entered\n",
    "    idx = indices[indices == name].index[0]\n",
    "    \n",
    "    # Find the restaurants with a similar cosine-sim value and order them from bigges number\n",
    "    score_series = pd.Series(cosine_similarities[idx]).sort_values(ascending=False)\n",
    "    \n",
    "    # Extract top 30 restaurant indexes with a similar cosine-sim value\n",
    "    top30_indexes = list(score_series.iloc[0:31].index)\n",
    "    \n",
    "    # Names of the top 30 restaurants\n",
    "    for each in top30_indexes:\n",
    "        recommend_restaurant.append(list(df_percent.index)[each])\n",
    "    \n",
    "    # Creating the new data set to show similar restaurants\n",
    "    df_new = pd.DataFrame(columns=['cuisines', 'Mean Rating', 'cost'])\n",
    "    \n",
    "    # Create the top 30 similar restaurants with some of their columns\n",
    "    for each in recommend_restaurant:\n",
    "        df_new = df_new.append(pd.DataFrame(df_percent[['cuisines','Mean Rating', 'cost']][df_percent.index == each].sample()))\n",
    "    \n",
    "    # Drop the same named restaurants and sort only the top 10 by the highest rating\n",
    "    df_new = df_new.drop_duplicates(subset=['cuisines','Mean Rating', 'cost'], keep=False)\n",
    "    df_new = df_new.sort_values(by='Mean Rating', ascending=False).head(10)\n",
    "    \n",
    "    print('TOP %s RESTAURANTS LIKE %s WITH SIMILAR REVIEWS: ' % (str(len(df_new)), name))\n",
    "    \n",
    "    return df_new\n",
    "recommend('Pai Vihar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": 0.014059,
     "end_time": "2021-03-27T12:22:33.504417",
     "exception": false,
     "start_time": "2021-03-27T12:22:33.490358",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 335.697414,
   "end_time": "2021-03-27T12:22:34.731535",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-03-27T12:16:59.034121",
   "version": "2.2.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
